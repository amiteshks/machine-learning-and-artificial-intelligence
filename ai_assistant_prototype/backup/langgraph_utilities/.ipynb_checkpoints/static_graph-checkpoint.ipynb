{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "497a0ce7-8ba6-40c3-b9c7-fa767b780db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from tool_agents import discharge_patient, get_patient_status\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f575e274-1df7-4c0e-9ede-88eca1538921",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [discharge_patient, get_patient_status]\n",
    "\n",
    "\n",
    "def ai_assistant_node (state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # print(f\"ai_assistant_node.last_message: {last_message}\")\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    llm_with_tools = llm.bind_tools(tools_list, parallel_tool_calls=False)\n",
    "    \n",
    "    # System message\n",
    "    sys_msg = SystemMessage(content=\"\"\"You are a helpful medical assistant. You can:\n",
    "    1. Help discharge patients using discharge_patient(patient_id)\n",
    "    2. Check patient status using get_patient_status(patient_id)\n",
    "    \"\"\")\n",
    "    \n",
    "    response = llm_with_tools.invoke([sys_msg] + state[\"messages\"])\n",
    "    \n",
    "    return_value = {\"messages\": state[\"messages\"] + [response]}\n",
    "    # print(f\"ai_assistant_node.return_value: {return_value}\")\n",
    "    return return_value\n",
    "\n",
    "def tools_node (state: MessagesState):\n",
    "    # print(f\"Starting tools_node.state: {state}\")\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    response = \"TOOLS RESPONSE\"\n",
    "    return_value = {\"messages\": state[\"messages\"] + [response]}\n",
    "    # print(f\"tools_node.return_value: {return_value}\")\n",
    "    return return_value\n",
    "\n",
    "    \n",
    "def should_go_to_tools_node (state: MessagesState):\n",
    "    # If last message is a tools_message, go to tools_node, else go to END\n",
    "    last_message = state[\"messages\"][-1]    \n",
    "    # print(f\"should_go_to_tools_node.last_message: {last_message}\")\n",
    "\n",
    "    return_value = \"\"\n",
    "    if getattr(last_message, \"tool_calls\", None):\n",
    "        return_value = \"to_tools_node\"\n",
    "    else:\n",
    "        return_value = \"to_end\" \n",
    "\n",
    "    return return_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0ba3aedb-d9ab-436a-9f73-9bcf9f984478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(\"ai_assistant_node\", ai_assistant_node)\n",
    "graph_builder.add_node(\"tools_node\", tools_node)\n",
    "graph_builder.set_entry_point(\"ai_assistant_node\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"ai_assistant_node\",\n",
    "    should_go_to_tools_node,\n",
    "    {\n",
    "        \"to_tools_node\": \"tools_node\",\n",
    "        \"to_end\": END\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge(\"tools_node\", \"ai_assistant_node\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(interrupt_before=['tools_node'], checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "58913140-68a7-4156-bb31-2997d1efa1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "state\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "35fbbcd3-9586-4ebc-865a-9e99a7cf6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "thread_id = 103\n",
    "initial_input = \"discharge patient with id 2222\"\n",
    "thread_config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "human_message = {\"messages\": [HumanMessage(content=initial_input)]}\n",
    "\n",
    "response = graph.invoke(human_message, config=thread_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dcc7748b-681f-4209-9b9b-c76cd9f5de68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='discharge patient with id 2222', additional_kwargs={}, response_metadata={}, id='03b53bcf-2f4b-4b99-bad1-76439519bc46'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cASyzd9VnlDxCJYoFuHIDwye', 'function': {'arguments': '{\"patient_id\":\"2222\"}', 'name': 'discharge_patient'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 146, 'total_tokens': 164, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7fcd609668', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d5bc698-2e49-4053-b609-dd6a2eb3c614-0', tool_calls=[{'name': 'discharge_patient', 'args': {'patient_id': '2222'}, 'id': 'call_cASyzd9VnlDxCJYoFuHIDwye', 'type': 'tool_call'}], usage_metadata={'input_tokens': 146, 'output_tokens': 18, 'total_tokens': 164, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2e50bf94-73d5-423e-bd29-aa9fd78508d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools_node',)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a4ad2fdc-f041-4a04-97a6-6e8882554ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools_node',)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "902af69f-e34a-4656-aed7-0e6581916a58",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_cASyzd9VnlDxCJYoFuHIDwye\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[247], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_response \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28;01mNone\u001b[39;00m, thread_config)\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2069\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2068\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2069\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2070\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2071\u001b[0m     config,\n\u001b[0;32m   2072\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2073\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2074\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2075\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2076\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2077\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2078\u001b[0m ):\n\u001b[0;32m   2079\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2080\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1724\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1724\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1725\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1726\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1727\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1728\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1729\u001b[0m         ):\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     run_with_retry(\n\u001b[0;32m    231\u001b[0m         t,\n\u001b[0;32m    232\u001b[0m         retry_policy,\n\u001b[0;32m    233\u001b[0m         configurable\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    234\u001b[0m             CONFIG_KEY_SEND: partial(writer, t),\n\u001b[0;32m    235\u001b[0m             CONFIG_KEY_CALL: partial(call, t),\n\u001b[0;32m    236\u001b[0m         },\n\u001b[0;32m    237\u001b[0m     )\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m task\u001b[38;5;241m.\u001b[39mproc\u001b[38;5;241m.\u001b[39minvoke(task\u001b[38;5;241m.\u001b[39minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:506\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    503\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    504\u001b[0m )\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 506\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:270\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 270\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[233], line 17\u001b[0m, in \u001b[0;36mai_assistant_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# System message\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sys_msg \u001b[38;5;241m=\u001b[39m SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a helpful medical assistant. You can:\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m1. Help discharge patients using discharge_patient(patient_id)\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124m2. Check patient status using get_patient_status(patient_id)\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m response \u001b[38;5;241m=\u001b[39m llm_with_tools\u001b[38;5;241m.\u001b[39minvoke([sys_msg] \u001b[38;5;241m+\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     19\u001b[0m return_value \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m [response]}\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# print(f\"ai_assistant_node.return_value: {return_value}\")\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5353\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5354\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5356\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:284\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    281\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    283\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    285\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    286\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    287\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    288\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    289\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    292\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    293\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    294\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:860\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    854\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    858\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    859\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:690\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 690\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    691\u001b[0m                 m,\n\u001b[0;32m    692\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    693\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    694\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    695\u001b[0m             )\n\u001b[0;32m    696\u001b[0m         )\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:925\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 925\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    926\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    927\u001b[0m         )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    929\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:790\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 790\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:850\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    810\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    847\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    848\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    849\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    851\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    852\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    853\u001b[0m             {\n\u001b[0;32m    854\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    855\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    856\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m    857\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    858\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    859\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    860\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    861\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m    862\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m    863\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    864\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m    865\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m    866\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    867\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m    868\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m    869\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    870\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m    871\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    872\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    873\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m    874\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    875\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m    876\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    877\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m    878\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    879\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    880\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    881\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m    882\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    883\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    884\u001b[0m             },\n\u001b[0;32m    885\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    886\u001b[0m         ),\n\u001b[0;32m    887\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    888\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    889\u001b[0m         ),\n\u001b[0;32m    890\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    891\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    893\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1282\u001b[0m     )\n\u001b[1;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    961\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    962\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    963\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    964\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    965\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    966\u001b[0m )\n",
      "File \u001b[1;32mC:\\Softwares\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1073\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_cASyzd9VnlDxCJYoFuHIDwye\", 'type': 'invalid_request_error', 'param': 'messages.[3].role', 'code': None}}",
      "\u001b[0mDuring task with name 'ai_assistant_node' and id '8f4c11df-da3c-3e76-5383-75f2eec535a6'"
     ]
    }
   ],
   "source": [
    "final_response = graph.invoke(None, thread_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b57dad58-6fc9-4812-873f-470b36408fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TOOLS RESPONSE'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "291bcee0-4284-4966-a38f-5a341b5b6fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='discharge patient with id 2222', additional_kwargs={}, response_metadata={}, id='03b53bcf-2f4b-4b99-bad1-76439519bc46'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cASyzd9VnlDxCJYoFuHIDwye', 'function': {'arguments': '{\"patient_id\":\"2222\"}', 'name': 'discharge_patient'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 146, 'total_tokens': 164, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7fcd609668', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d5bc698-2e49-4053-b609-dd6a2eb3c614-0', tool_calls=[{'name': 'discharge_patient', 'args': {'patient_id': '2222'}, 'id': 'call_cASyzd9VnlDxCJYoFuHIDwye', 'type': 'tool_call'}], usage_metadata={'input_tokens': 146, 'output_tokens': 18, 'total_tokens': 164, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='TOOLS RESPONSE', additional_kwargs={}, response_metadata={}, id='b9528d6d-ffd5-4c59-a4a5-00bf690512d1')]}, next=('ai_assistant_node',), config={'configurable': {'thread_id': 103, 'checkpoint_ns': '', 'checkpoint_id': '1eff2eca-f0c2-65ca-8002-ca23eaf4f011'}}, metadata={'source': 'loop', 'writes': {'tools_node': {'messages': [HumanMessage(content='discharge patient with id 2222', additional_kwargs={}, response_metadata={}, id='03b53bcf-2f4b-4b99-bad1-76439519bc46'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cASyzd9VnlDxCJYoFuHIDwye', 'function': {'arguments': '{\"patient_id\":\"2222\"}', 'name': 'discharge_patient'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 146, 'total_tokens': 164, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_7fcd609668', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3d5bc698-2e49-4053-b609-dd6a2eb3c614-0', tool_calls=[{'name': 'discharge_patient', 'args': {'patient_id': '2222'}, 'id': 'call_cASyzd9VnlDxCJYoFuHIDwye', 'type': 'tool_call'}], usage_metadata={'input_tokens': 146, 'output_tokens': 18, 'total_tokens': 164, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), 'TOOLS RESPONSE']}}, 'thread_id': 103, 'step': 2, 'parents': {}}, created_at='2025-02-24T20:19:43.478727+00:00', parent_config={'configurable': {'thread_id': 103, 'checkpoint_ns': '', 'checkpoint_id': '1eff2eca-d974-6506-8001-a56ba129f9bd'}}, tasks=(PregelTask(id='8f4c11df-da3c-3e76-5383-75f2eec535a6', name='ai_assistant_node', path=('__pregel_pull', 'ai_assistant_node'), error='BadRequestError(\\'Error code: 400 - {\\\\\\'error\\\\\\': {\\\\\\'message\\\\\\': \"An assistant message with \\\\\\'tool_calls\\\\\\' must be followed by tool messages responding to each \\\\\\'tool_call_id\\\\\\'. The following tool_call_ids did not have response messages: call_cASyzd9VnlDxCJYoFuHIDwye\", \\\\\\'type\\\\\\': \\\\\\'invalid_request_error\\\\\\', \\\\\\'param\\\\\\': \\\\\\'messages.[3].role\\\\\\', \\\\\\'code\\\\\\': None}}\\')', interrupts=(), state=None, result=None),))"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = graph.get_state(thread_config)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "68512f04-9d2c-4772-a187-8c6d716d4f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ai_assistant_node',)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff1dd3-0eab-48ad-baf0-f63c25eb913e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
